{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James Elder & Mark M Thompson - The English Actor\n",
      "Load OK\n",
      "np.array OK\n",
      "stereoToMono OK\n",
      "Avant STFT\n",
      "AprÃ¨s STFT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laly/alligator/local/lib/python3.5/site-packages/torch/nn/functional.py:1749: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "from pydub import AudioSegment\n",
    "from scipy import signal,stats\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from pydub import playback\n",
    "from pydub import generators\n",
    "import array\n",
    "import time\n",
    "import musdb\n",
    "from torch.utils import data\n",
    "import math\n",
    "import Net\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "mus = musdb.DB(root_dir=\"/mnt/scratch/lts2/laly/musdb\")\n",
    "\n",
    "\n",
    "\n",
    "######################################################################################################################  \n",
    "    \n",
    "\n",
    "def DANN_train(track):\n",
    "\n",
    "    estimates = {}\n",
    "\n",
    "    net = torch.load('DANN.pt')\n",
    "    \n",
    "    net.to(device)\n",
    "\n",
    "    fs = 44100/5\n",
    "    \n",
    "    track_i = np.array(track.audio)\n",
    "    track_v = np.array(track.targets['vocals'].audio)\n",
    "    track_d = np.array(track.targets['drums'].audio)\n",
    "    track_b = np.array(track.targets['bass'].audio)\n",
    "    track_o = np.array(track.targets['other'].audio)\n",
    "    \n",
    "    track_i = (track_i[:,0]+track_i[:,1])/2\n",
    "    track_v = (track_v[:,0]+track_v[:,1])/2\n",
    "    track_d = (track_d[:,0]+track_d[:,1])/2\n",
    "    track_b = (track_b[:,0]+track_b[:,1])/2\n",
    "    track_o = (track_o[:,0]+track_o[:,1])/2\n",
    "    \n",
    "    track_i = signal.resample(track_i,len(track_i)//5,window = 'hamming')\n",
    "    track_v = signal.resample(track_v,len(track_v)//5,window = 'hamming')\n",
    "    track_d = signal.resample(track_d,len(track_d)//5,window = 'hamming')\n",
    "    track_b = signal.resample(track_b,len(track_b)//5,window = 'hamming')\n",
    "    track_o = signal.resample(track_o,len(track_o)//5,window = 'hamming') \n",
    "    \n",
    "    f, t, Sxx_noised = signal.stft(track_i, fs, 'hamming',2048,1024,2048)\n",
    "    \n",
    "    Sxx_real_noised = np.real(Sxx_noised)*100000\n",
    "    Sxx_imag_noised = np.imag(Sxx_noised)*100000\n",
    "    \n",
    "    z_output_vocal = [[0 for l in range(len(Sxx_real_noised[0]))] for k in range(1025)]\n",
    "    z_o = torch.Tensor(z_output_vocal)\n",
    "    z_output_vocal = z_o.detach().numpy()\n",
    "    z_output_drums = [[0 for l in range(len(Sxx_real_noised[0]))] for k in range(1025)]\n",
    "    z_o = torch.Tensor(z_output_drums)\n",
    "    z_output_drums = z_o.detach().numpy()\n",
    "    z_output_bass = [[0 for l in range(len(Sxx_real_noised[0]))] for k in range(1025)]\n",
    "    z_o = torch.Tensor(z_output_bass)\n",
    "    z_output_bass = z_o.detach().numpy()\n",
    "    \n",
    "    criterion = nn.L1Loss()\n",
    "    criterion_GPU = criterion.to(device)\n",
    "\n",
    "    for i in range(0,len(Sxx_real_noised[0]),88):\n",
    "        \n",
    "        Sxx_real_noised_i = Sxx_real_noised[:,i:i+88]\n",
    "        Sxx_imag_noised_i = Sxx_imag_noised[:,i:i+88]\n",
    "\n",
    "        Sxx_torch_noised = (torch.Tensor([[Sxx_real_noised_i,Sxx_imag_noised_i]]))\n",
    "\n",
    "        if Sxx_torch_noised.size()[3] == 88:\n",
    "           \n",
    "            Sxx_torch_GPU_noised = Sxx_torch_noised.to(device)\n",
    "            \n",
    "            outputs_GPU = net(Sxx_torch_GPU_noised)\n",
    "            \n",
    "            outputs = outputs_GPU.cpu()\n",
    "            outputs = outputs.detach().numpy()\n",
    "            Sxx_torch_noised = Sxx_torch_noised.detach().numpy()\n",
    "            outputs = [[Sxx_torch_noised[0][0]*outputs[0][0],Sxx_torch_noised[0][1]*outputs[0][1],Sxx_torch_noised[0][0]*outputs[0][2],Sxx_torch_noised[0][1]*outputs[0][3],Sxx_torch_noised[0][0]*outputs[0][4],Sxx_torch_noised[0][1]*outputs[0][5]]]  \n",
    "            \n",
    "            z_output_vocal = z_output_vocal.astype(complex)\n",
    "            z_output_vocal[:,i:i+88] = (outputs[0][0] + 1j*outputs[0][1])/50000\n",
    "            z_output_drums = z_output_drums.astype(complex)\n",
    "            z_output_drums[:,i:i+88] = (outputs[0][2] + 1j*outputs[0][3])/20000\n",
    "            z_output_bass = z_output_bass.astype(complex)\n",
    "            z_output_bass[:,i:i+88] = (outputs[0][4] + 1j*outputs[0][5])/20000\n",
    "    \n",
    "    t, track_output_vocal = signal.istft(z_output_vocal,fs,'hamming',2048,1024,2048)\n",
    "    t, track_output_drums = signal.istft(z_output_drums,fs,'hamming',2048,1024,2048)\n",
    "    t, track_output_bass = signal.istft(z_output_bass,fs,'hamming',2048,1024,2048)\n",
    "    \n",
    "    track_output_vocal = signal.resample(track_output_vocal, len(track_output_vocal)*5,window = 'hamming')\n",
    "    track_output_drums = signal.resample(track_output_drums, len(track_output_drums)*5,window = 'hamming')\n",
    "    track_output_bass = signal.resample(track_output_bass, len(track_output_bass)*5,window = 'hamming')\n",
    "    track_v = signal.resample(track_v,len(track_v)*5,window = 'hamming')\n",
    "    track_d = signal.resample(track_d,len(track_d)*5,window = 'hamming')\n",
    "    track_b = signal.resample(track_b,len(track_b)*5,window = 'hamming')\n",
    "    track_o = signal.resample(track_o,len(track_o)*5,window = 'hamming')\n",
    "    \n",
    "    track_output_vocal = track_output_vocal[0:len(track_v)]\n",
    "    track_d = track_d[0:len(track_output_vocal)]\n",
    "    track_b = track_b[0:len(track_output_vocal)]\n",
    "    track_o = track_o[0:len(track_output_vocal)]\n",
    "    \n",
    "    estimates = {\n",
    "        track.name + '_vocals' : track_output_vocal,\n",
    "        track.name + '_drums' : track_output_drums, \n",
    "        track.name + '_bass' : track_output_bass, \n",
    "    }\n",
    "    \n",
    "    return estimates\n",
    "\n",
    "\n",
    "mus.run(CNN_train, subsets=\"test\", estimates_dir=None) #estimates_dir=\"laly@lts2gdk0:/mnt/scratch/lts2/laly_test\" if you want to listen to the output songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
